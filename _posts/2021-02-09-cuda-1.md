---
layout: post
title:  "CUDA Programming 簡介（一）"
---

`CUDA`為`Compute Unified Device Architecture`的縮寫，是`nVidia`推出開發`GPGPU`的一種技術。
與他相似的技術有`OpenCL`等等。

但無論是`CUDA`還是`OpenCL`精神上都是一樣的：
1. 分配`device`記憶體
2. 丟進`device`運算
3. 把結果倒回`host`

在`CUDA`上執行的程式稱為`kernel`，都是由`CUDA`內的`thread` **平行** 執行。
其中，三維的`thread`組成`block`，三維的`block`組成`grid`。

利用多個`thread`平行印出`Hello World`：
```c++=
#include <stdio.h>
#include <cuda.h>

__global__ void dkernel()
{
    printf("Hello World\n");
}

int main(void)
{
    dim3 grid(1, 1, 1);   // 每個 grid 有 1*1*1 個block
    dim3 block(4, 1, 1);  // 每個 block 有 4*1*1 個 thread
                          // 總共 1*1*1*4*1*1 = 4 個 thread
    dkernel<<<grid, block>>>();
    cudaThreadSynchronize();

    return 0;
}
```
結果：
```bash=
Hello World
Hello World
Hello World
Hello World
```

可以利用`thread id`來對不同記憶體位置做操作。
```c++=
#include <stdio.h>
#include <cuda.h>

__global__ void dkernel(unsigned* matrix)
{
    unsigned id = blockId.x * blockDim.x + threadIdx.x;
    matrix[id] = id;
}

int main()
{
    dim3 grid(4, 1, 1);
    dim3 block(8, 1, 1);
    unsigned* matrix;
    unsigned* hmatrix;
    // 分配device記憶體
    cudaMalloc(&matrix, 4 * 8 * sizeof(unsigned));
    hmatrix = (unsigned*)malloc(4 * 8 * sizeof(unsigned));
    // 丟進device運算
    dkernel <<<grid, block>>>(matrix);
    // 把結果倒回host
    cudaMemcpy(hmatrix, matrix, 4 * 8 * sizeof(unsigned), cudaMemcpyDeviceToHost);

    for (unsigned i = 0; i < 4; i++) {
        for (unsigned j = 0; j < 8; j++) {
            printf("%2d", hmatrix[i * 8 + j]);
        }
        printf("\n");
    }
    return 0;
}
```
結果：
```bash=
 0  1  2  3  4  5  6  7
 8  9 10 11 12 13 14 15
16 17 18 19 20 21 22 23
24 25 26 27 28 29 30 31
```

圖解：
<img src="/assets/images/2021-02-09-cuda-1/section1.png" width="1300">

<img src="/assets/images/2021-02-09-cuda-1/section2.png" width="1300">

## References:

[nVidia CUDA C/C++ Basics](https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf)

[GPU Programming](https://www.cse.iitm.ac.in/~rupesh/teaching/gpu/aug17/2-computation.pdf)
