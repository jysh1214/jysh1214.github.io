---
layout: post
title:  "CUDA Programming 簡介（二）"
---

利用`CUDA`實作`M`階矩陣平方。

版本一：使用`M`個`thread`。
```c++=
/**
 * 利用 thread id 歷遍所有 row ，再利用 for loop 歷遍所有 col
 */
__global__ void sqaure(unsigned* matrix, unsigned* result, unsigned matrixsize)
{
    unsigned id = blockIdx.x * blockDim.x + threadIdx.x;
    for (unsigned jj = 0; jj < matrixsize; ++jj) {
        for (unsigned kk = 0; kk < matrixsize; ++kk) {
            result[id * matrixsize + jj] +=  
                matrix[id * matrixsize + kk] * matrix[kk * matrixsize + jj];
        }
    }
}
```
完整程式碼：
```c++=
#include <stdio.h>
#include <cuda.h>

__global__ void square(unsigned* matrix, unsigned* result, unsigned matrixsize)
{
    unsigned id = blockIdx.x * blockDim.x + threadIdx.x;
    for (unsigned jj = 0; jj < matrixsize; ++jj) {
        for (unsigned kk = 0; kk < matrixsize; ++kk) {
            result[id * matrixsize + jj] +=
                matrix[id * matrixsize + kk] * matrix[kk * matrixsize + jj];
        }
    }
}

#define N 1000000
#define M 1000

int main(void)
{
    unsigned* hmatrix = (unsigned*)malloc(N * sizeof(unsigned));
    for (unsigned i = 0; i < N; ++i) {
        hmatrix[i] = i % 10;
    }

    unsigned* hresult = (unsigned*)malloc(N * sizeof(unsigned));

    unsigned* dmatrix;
    unsigned* dresult;

    cudaMalloc(&dmatrix, N * sizeof(unsigned));
    cudaMalloc(&dresult, N * sizeof(unsigned));

    cudaMemcpy(dmatrix, hmatrix, N * sizeof(unsigned), cudaMemcpyHostToDevice);

    dim3 grid(1, 1, 1);
    dim3 block(M, 1, 1);

    square<<<grid, block>>>(dmatrix, dresult, M);
    cudaMemcpy(hresult, dresult, N * sizeof(unsigned), cudaMemcpyDeviceToHost);

    free(hmatrix);
    free(hresult);

    cudaFree(dmatrix);
    cudaFree(dresult);

    return 0;
}
```

版本二：使用`M*M`個`thread`。
```c++=
/**
 * 利用 thread id 歷遍所有 elements
 */
__global__ void sqaure(unsigned* matrix, unsigned* result, unsigned matrixsize)
{
    unsigned id = blockIdx.x * blockDim.x + threadIdx.x;
    unsigned i = id / matrixsize;
    unsigned j = id % matrixsize;

    for (unsigned k = 0; k < matrixsize; ++k) {
        result[i * matrixsize + j] += matrix[i * matrixsize + k] * matrix[k * matrixsize + j];
    }
}
```
完整程式碼：
```c++=
#include <stdio.h>
#include <cuda.h>

__global__ void square(unsigned* matrix, unsigned* result, unsigned matrixsize)
{
    unsigned id = blockIdx.x * blockDim.x + threadIdx.x;
    for (unsigned jj = 0; jj < matrixsize; ++jj) {
        for (unsigned kk = 0; kk < matrixsize; ++kk) {
            result[id * matrixsize + jj] +=
                matrix[id * matrixsize + kk] * matrix[kk * matrixsize + jj];
        }
    }
}

#define N 1000000
#define M 1000

int main(void)
{
    unsigned* hmatrix = (unsigned*)malloc(N * sizeof(unsigned));
    for (unsigned i = 0; i < N; ++i) {
        hmatrix[i] = i % 10;
    }

    unsigned* hresult = (unsigned*)malloc(N * sizeof(unsigned));

    unsigned* dmatrix;
    unsigned* dresult;

    cudaMalloc(&dmatrix, N * sizeof(unsigned));
    cudaMalloc(&dresult, N * sizeof(unsigned));

    cudaMemcpy(dmatrix, hmatrix, N * sizeof(unsigned), cudaMemcpyHostToDevice);

    dim3 grid(M, 1, 1);
    dim3 block(M, 1, 1);

    square<<<grid, block>>>(dmatrix, dresult, M);
    cudaMemcpy(hresult, dresult, N * sizeof(unsigned), cudaMemcpyDeviceToHost);

    free(hmatrix);
    free(hresult);

    cudaFree(dmatrix);
    cudaFree(dresult);

    return 0;
}
```

實作`1000`階矩陣平方，比較兩個版本差異效能差異：
- v1
```bash=
real	0m2.414s
user	0m2.156s
sys 	0m0.217s
```
- v2
```bash=
real	0m0.284s
user	0m0.024s
sys	    0m0.232s
```

## References:

[nVidia CUDA C/C++ Basics](https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf)

[GPU Programming](https://www.cse.iitm.ac.in/~rupesh/teaching/gpu/aug17/2-computation.pdf)
